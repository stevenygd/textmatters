{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Experiments\n",
    "\n",
    "Run experiments on a larger data-set using basic ablation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Grendel/Desktop/ML/textmatters'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports \n",
    "CWD = %pwd\n",
    "CWD = str(CWD)\n",
    "\n",
    "import json\n",
    "from six.moves import cPickle\n",
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "\n",
    "from IPython.core.display import HTML \n",
    "from IPython.core.display import Image, display, display_pretty\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:02.701272\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "COCO_TEXT_PATH = os.path.join(CWD, 'coco-text')\n",
    "sys.path.insert(0, COCO_TEXT_PATH)\n",
    "import coco_text as ct\n",
    "ct = ct.COCO_Text(COCO_PATH + 'COCO_Text.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Coco data (Train)\n",
    "\"\"\"\n",
    "COCO_PATH = os.path.join(CWD,'data','coco')\n",
    "COCO_ANNO_PATH = os.path.join(COCO_PATH, 'annotations')\n",
    "\n",
    "# load the data from captions\n",
    "with open(os.path.join(COCO_ANNO_PATH, 'captions_train2014.json')) as f:\n",
    "    coco_captions = json.load(f)\n",
    "\n",
    "# build the reverse dictionary, from img_id to captions, img_infos, and annotations\n",
    "img_ids = []\n",
    "img_captions = {}\n",
    "for img_info in coco_captions['images']:\n",
    "    mid = int(img_info['id'])\n",
    "    img_ids.append(mid)\n",
    "    if not mid in img_captions:\n",
    "        img_captions[mid] = {}\n",
    "    img_captions[mid]['image'] = img_info\n",
    "\n",
    "for cap_info in coco_captions['annotations']:\n",
    "    mid = int(cap_info['image_id'])\n",
    "    if not 'annotation' in img_captions[mid]:\n",
    "        img_captions[mid]['annotation'] = []\n",
    "    img_captions[mid]['annotation'].append(cap_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Texts:\t61247;\t\tRelevant Text:\t5556\t\tNo relevant text:\t15980\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split into three groups:\n",
    "    1. Groups with no text instances\n",
    "    2. Groups with relevant COCO-Text Instance \n",
    "       (the text in the instance also appears in the caption)\n",
    "    3. Groups without relevant COCO-Text Instance\n",
    "\"\"\"\n",
    "no_texts     = []\n",
    "rel_texts    = []\n",
    "no_rel_texts = []\n",
    "for mid in img_ids:    \n",
    "    #  get text annotations\n",
    "    anns = [ann for ann in ct.loadAnns(ct.getAnnIds(imgIds=mid)) if 'utf8_string' in ann ]\n",
    "    if len(anns) == 0:\n",
    "        no_texts.append(mid)\n",
    "        continue\n",
    "        \n",
    "    # split text instances into words\n",
    "    text_words = set([w.strip('.').upper() for ann in anns for w in ann['utf8_string'].split(' ')])\n",
    "\n",
    "    # split captions into words\n",
    "    caps = [ note['caption'] for note in img_captions[mid]['annotation']]\n",
    "    caps_words = set([word.strip('.').upper() for word in (' '.join(caps).split())])\n",
    "\n",
    "    if len(text_words & caps_words) > 0:\n",
    "        rel_texts.append(mid)\n",
    "    else:\n",
    "        no_rel_texts.append(mid)\n",
    "\n",
    "with open(os.path.join(CWD, 'input', 'no_texts_img_ids.pkl'),'w+') as f:\n",
    "    cPickle.dump(no_texts, f)\n",
    "\n",
    "with open(os.path.join(CWD, 'input', 'rel_texts_img_ids.pkl'),'w+') as f:\n",
    "    cPickle.dump(rel_texts, f)\n",
    "    \n",
    "with open(os.path.join(CWD, 'input', 'no_rel_texts_img_ids.pkl'),'w+') as f:\n",
    "    cPickle.dump(no_rel_texts, f)\n",
    "    \n",
    "print \"No Texts:\\t%d;\\t\\tRelevant Text:\\t%d\\t\\tNo relevant text:\\t%d\"%(len(no_texts), len(rel_texts), len(no_rel_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
