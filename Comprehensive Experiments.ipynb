{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Experiments\n",
    "\n",
    "Run experiments on a larger data-set using basic ablation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Grendel/Desktop/ML/textmatters'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports \n",
    "CWD = %pwd\n",
    "CWD = str(CWD)\n",
    "\n",
    "import json\n",
    "from six.moves import cPickle\n",
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "\n",
    "from IPython.core.display import HTML \n",
    "from IPython.core.display import Image, display, display_pretty\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pipeline\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:02.588224\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "COCO_PATH = os.path.join(CWD,'data','coco')\n",
    "COCO_ANNO_PATH = os.path.join(COCO_PATH, 'annotations')\n",
    "COCO_TEXT_PATH = os.path.join(CWD, 'coco-text')\n",
    "sys.path.insert(0, COCO_TEXT_PATH)\n",
    "import coco_text as ct\n",
    "ct = ct.COCO_Text(os.path.join(COCO_PATH, 'COCO_Text.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Coco data (Train)\n",
    "\"\"\"\n",
    "# load the data from captions\n",
    "with open(os.path.join(COCO_ANNO_PATH, 'captions_train2014.json')) as f:\n",
    "    coco_captions = json.load(f)\n",
    "\n",
    "# build the reverse dictionary, from img_id to captions, img_infos, and annotations\n",
    "img_ids = []\n",
    "img_captions = {}\n",
    "for img_info in coco_captions['images']:\n",
    "    mid = int(img_info['id'])\n",
    "    img_ids.append(mid)\n",
    "    if not mid in img_captions:\n",
    "        img_captions[mid] = {}\n",
    "    img_captions[mid]['image'] = img_info\n",
    "\n",
    "for cap_info in coco_captions['annotations']:\n",
    "    mid = int(cap_info['image_id'])\n",
    "    if not 'annotation' in img_captions[mid]:\n",
    "        img_captions[mid]['annotation'] = []\n",
    "    img_captions[mid]['annotation'].append(cap_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Texts:\t61247;\t\tRelevant Text:\t5556\t\tNo relevant text:\t15980\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split into three groups:\n",
    "    1. Groups with no text instances\n",
    "    2. Groups with relevant COCO-Text Instance \n",
    "       (the text in the instance also appears in the caption)\n",
    "    3. Groups without relevant COCO-Text Instance\n",
    "\"\"\"\n",
    "no_texts     = []\n",
    "rel_texts    = []\n",
    "no_rel_texts = []\n",
    "for mid in img_ids:    \n",
    "    #  get text annotations\n",
    "    anns = [ann for ann in ct.loadAnns(ct.getAnnIds(imgIds=mid)) if 'utf8_string' in ann ]\n",
    "    if len(anns) == 0:\n",
    "        no_texts.append(mid)\n",
    "        continue\n",
    "        \n",
    "    # split text instances into words\n",
    "    text_words = set([w.strip('.').upper() for ann in anns for w in ann['utf8_string'].split(' ')])\n",
    "\n",
    "    # split captions into words\n",
    "    caps = [ note['caption'] for note in img_captions[mid]['annotation']]\n",
    "    caps_words = set([word.strip('.').upper() for word in (' '.join(caps).split())])\n",
    "\n",
    "    if len(text_words & caps_words) > 0:\n",
    "        rel_texts.append(mid)\n",
    "    else:\n",
    "        no_rel_texts.append(mid)\n",
    "\n",
    "with open(os.path.join(CWD, 'input', 'no_texts_img_ids.pkl'),'w+') as f:\n",
    "    cPickle.dump(no_texts, f)\n",
    "\n",
    "with open(os.path.join(CWD, 'input', 'rel_texts_img_ids.pkl'),'w+') as f:\n",
    "    cPickle.dump(rel_texts, f)\n",
    "    \n",
    "with open(os.path.join(CWD, 'input', 'no_rel_texts_img_ids.pkl'),'w+') as f:\n",
    "    cPickle.dump(no_rel_texts, f)\n",
    "    \n",
    "print \"No Texts:\\t%d;\\t\\tRelevant Text:\\t%d\\t\\tNo relevant text:\\t%d\"%(len(no_texts), len(rel_texts), len(no_rel_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IN_FILE_NAME  = 'high_coexist_img_ids.pkl'\n",
    "OUT_FILE_NAME = 'highexist_gaussian'\n",
    "IN_DIR        = 'input'\n",
    "OUT_DIR       = 'output'\n",
    "\n",
    "def get_stat(data):\n",
    "    if len(data)==0: return;\n",
    "    print \"\"\n",
    "    print \"Total:\\t%d;\\t\\tMean:\\t\\t%f;\\tNonezero:\\t%d\"%(len(data), statistics.mean(data), len(filter(lambda x:x!=0, data)))\n",
    "    print \"Median:\\t%f;\\tMedian(H):\\t%f;\\tMedian(L):\\t%f;\"%(statistics.median(data), statistics.median_high(data), statistics.median_low(data))\n",
    "    try:\n",
    "        variance = statistics.stdev(data)\n",
    "    except:\n",
    "        variance = 0\n",
    "    print \"Max:\\t%f;\\tMin:\\t\\t%f;\\tStd:\\t\\t%f\"%(max(data), min(data),variance)\n",
    "    print \"\\n\"\n",
    "    \n",
    "def look_up_image(title, idx, in_ids, vis, scores, out_file):\n",
    "    print \"[%d]%s\\n\"%(idx,title)\n",
    "    print \"\\tScore:%s;\\tImageId:%s\\n\"%(scores[idx], in_ids[idx])\n",
    "    print \"\\tOriginal Caption:\\n\\t\\t%s;\\n\\tAblation Caption:\\n\\t\\t%s;\"%(vis[idx*2+1]['caption'],vis[idx*2]['caption'])\n",
    "    print \"\\tAnnotated Captions:\\n\"\n",
    "    img_id = int(in_ids[idx])\n",
    "    for i, note in enumerate(img_captions[img_id]['annotation']):\n",
    "        print \"\\t\\t%d. %s\\n\"%(i+1, str(note['caption']).strip())\n",
    "    \n",
    "    # Display images side by side: http://permalink.gmane.org/gmane.comp.python.ipython.devel/11073\n",
    "    s = \"\"\"<table>\n",
    "        <tr>\n",
    "        <th><img src=\"%s\" style=\"max-width:400px\" /></th>\n",
    "        <th><img src=\"%s\" style=\"max-width:400px\" /></th>\n",
    "        </tr></table>\"\"\"%(img_captions[img_id]['image']['coco_url'], \"%s\"%os.path.join(\"tmp_%s\"%out_file, \"%s_%s_ablt.jpg\"%(str(idx).zfill(16),str(img_id))))\n",
    "    t=HTML(s)\n",
    "    display(t)\n",
    "\n",
    "def get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME, in_path=IN_DIR, out_path=OUT_DIR, num=3):\n",
    "    in_ids  = cPickle.load(open(os.path.join(in_path, in_file)))\n",
    "    scores  = cPickle.load(open(os.path.join(out_path, \"scores_%s.pkl\"%out_file)))\n",
    "    vis     = json.load(open(os.path.join(out_path, 'vis_%s.json'%out_file)))\n",
    "#     print \"Statistics for scores of gaussian filtered ablations:\"\n",
    "    get_stat(scores)\n",
    "\n",
    "    scores_idx = zip(range(len(scores)), scores[:len(in_ids)*2])\n",
    "    sorted_scores_idx = sorted(scores_idx, key=lambda x: x[1])   # sort by score\n",
    "    for idx, _ in sorted_scores_idx[:num]:\n",
    "        look_up_image(\"Iamges with lowest scores:\",idx, in_ids, vis, scores, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total:\t5600;\t\tMean:\t\t0.076921;\tNonezero:\t2820\n",
      "Median:\t0.066667;\tMedian(H):\t0.066667;\tMedian(L):\t0.066667;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.119841\n",
      "\n",
      "\n",
      "[0]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:222016\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man riding a motorcycle with a woman on the back;\n",
      "\tAblation Caption:\n",
      "\t\ta picture of a person holding a cell phone;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. a big red telephone booth that a man is standing in\n",
      "\n",
      "\t\t2. a person standing inside of a phone booth\n",
      "\n",
      "\t\t3. this is an image of a man in a phone booth.\n",
      "\n",
      "\t\t4. A man is standing in a red phone booth.\n",
      "\n",
      "\t\t5. A man using a phone in a phone booth.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/222016\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_rel_texts_gaussian/0000000000000000_222016_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:257350\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta close up of an orange and a banana;\n",
      "\tAblation Caption:\n",
      "\t\ta bus is parked in a parking lot;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. a group of people riding bikes stopped in front of a building\n",
      "\n",
      "\t\t2. A group of people on bicy les in front of a church.\n",
      "\n",
      "\t\t3. Bike riders on the corner outside of a church.\n",
      "\n",
      "\t\t4. Several children on bicycles outside a white church.\n",
      "\n",
      "\t\t5. Several people on bikes in front of a building.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/257350\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_rel_texts_gaussian/0000000000000002_257350_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:311914\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta lunch box with a variety of food;\n",
      "\tAblation Caption:\n",
      "\t\ta man standing in front of a truck;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A school bus parked with it's stop sign closed.\n",
      "\n",
      "\t\t2. A stop sign is on the side of a school bus.\n",
      "\n",
      "\t\t3. a bus sits stopped with a sign on the side of it\n",
      "\n",
      "\t\t4. Side of a school bus showing a stop sign.\n",
      "\n",
      "\t\t5. A view of a stop sign, on the side of a bus.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/311914\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_rel_texts_gaussian/0000000000000003_311914_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IN_FILE_NAME  = \"rel_texts_img_ids.pkl\"\n",
    "OUT_FILE_NAME = \"rel_texts_gaussian\"\n",
    "# pipeline.run(amode=\"gaussian\", input_file=IN_FILE_NAME, output_file=OUT_FILE_NAME)\n",
    "get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IN_FILE_NAME  = \"rel_texts_img_ids.pkl\"\n",
    "OUT_FILE_NAME = \"rel_texts_blackout\"\n",
    "# pipeline.run(amode=\"blackout\", input_file=IN_FILE_NAME, output_file=OUT_FILE_NAME)\n",
    "get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IN_FILE_NAME  = \"no_rel_texts_img_ids.pkl\"\n",
    "OUT_FILE_NAME = \"no_rel_texts_blackout\"\n",
    "# pipeline.run(amode=\"blackout\", input_file=IN_FILE_NAME, output_file=OUT_FILE_NAME)\n",
    "get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total:\t16000;\t\tMean:\t\t0.056330;\tNonezero:\t6704\n",
      "Median:\t0.000000;\tMedian(H):\t0.000000;\tMedian(L):\t0.000000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.094949\n",
      "\n",
      "\n",
      "[0]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:392136\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man with a hat and a hat on a clock;\n",
      "\tAblation Caption:\n",
      "\t\ta group of people standing next to each other;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A large bus and some people on the street.\n",
      "\n",
      "\t\t2. Several people are standing on the sidewalk as a bus goes by.\n",
      "\n",
      "\t\t3. Bus rushing by a group of people walking in a city.\n",
      "\n",
      "\t\t4. A double-decker bus moving down the street as people stand waiting.\n",
      "\n",
      "\t\t5. A group of people standing next to a yellow and blue double decker bus.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/392136\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_no_rel_texts_blackout/0000000000000000_392136_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:71631\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man and a woman standing next to each other;\n",
      "\tAblation Caption:\n",
      "\t\ta truck is parked in a parking lot;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. Dining room table set for a casual meal, with flowers.\n",
      "\n",
      "\t\t2. A red table topped with four white place mats.\n",
      "\n",
      "\t\t3. there is a dining room table with a red cloth and a vase with roses\n",
      "\n",
      "\t\t4. a table with a red tablecloth and white placemats\n",
      "\n",
      "\t\t5. A small dinning table with all red napkins and a red table cloth .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/71631\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_no_rel_texts_blackout/0000000000000002_71631_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:279108\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta desk with a laptop and a keyboard;\n",
      "\tAblation Caption:\n",
      "\t\ta bus is driving down the street in a city;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A woman feeding a man food from a spoon.\n",
      "\n",
      "\t\t2. A woman offering a man a taste of something in front of other people.\n",
      "\n",
      "\t\t3. A woman feeds a man a bite of food.\n",
      "\n",
      "\t\t4. a woman is feeding something to a man\n",
      "\n",
      "\t\t5. A woman spoon feeding an old man\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/279108\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_no_rel_texts_blackout/0000000000000004_279108_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[392136,\n",
       " 37015,\n",
       " 71631,\n",
       " 491269,\n",
       " 279108,\n",
       " 438422,\n",
       " 485894,\n",
       " 299411,\n",
       " 239811,\n",
       " 287541,\n",
       " 540162,\n",
       " 357684,\n",
       " 576757,\n",
       " 98760,\n",
       " 77806,\n",
       " 280980,\n",
       " 62604,\n",
       " 217306,\n",
       " 374114,\n",
       " 560459,\n",
       " 448698,\n",
       " 70868,\n",
       " 513541,\n",
       " 239728,\n",
       " 474882,\n",
       " 483008,\n",
       " 424102,\n",
       " 77375,\n",
       " 212091]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_FILE_NAME  = \"no_rel_texts_img_ids.pkl\"\n",
    "OUT_FILE_NAME = \"no_rel_texts_blackout\"\n",
    "# pipeline.run(amode=\"gaussian\", input_file=IN_FILE_NAME, output_file=OUT_FILE_NAME)\n",
    "get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME)\n",
    "\n",
    "\n",
    "in_ids  = cPickle.load(open(os.path.join(IN_DIR, IN_FILE_NAME)))\n",
    "scores  = cPickle.load(open(os.path.join(OUT_DIR, \"scores_%s.pkl\"%OUT_FILE_NAME)))\n",
    "vis     = json.load(open(os.path.join(OUT_DIR, 'vis_%s.json'%OUT_FILE_NAME)))\n",
    "\n",
    "selected_ids = in_ids[:29]\n",
    "selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up\n",
      "loading annotations into memory...\n",
      "0:00:04.272789\n",
      "creating index...\n",
      "index created!\n",
      "Ablating image 1/30\n",
      "Ablating image 2/30\n",
      "Ablating image 3/30\n",
      "Ablating image 4/30\n",
      "Ablating image 5/30\n",
      "Ablating image 6/30\n",
      "Ablating image 7/30\n",
      "Ablating image 8/30\n",
      "Ablating image 9/30\n",
      "Ablating image 10/30\n",
      "Ablating image 11/30\n",
      "Ablating image 12/30\n",
      "Ablating image 13/30\n",
      "Ablating image 14/30\n",
      "Ablating image 15/30\n",
      "Ablating image 16/30\n",
      "Ablating image 17/30\n",
      "Ablating image 18/30\n",
      "Ablating image 19/30\n",
      "Ablating image 20/30\n",
      "Ablating image 21/30\n",
      "Ablating image 22/30\n",
      "Ablating image 23/30\n",
      "Ablating image 24/30\n",
      "Ablating image 25/30\n",
      "Ablating image 26/30\n",
      "Ablating image 27/30\n",
      "Ablating image 28/30\n",
      "Ablating image 29/30\n",
      "Ablating image 30/30\n",
      "DataLoaderRaw loading images from folder: \t/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout\t\n",
      "\n",
      "listing all images in directory /Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout\t\n",
      "\n",
      "DataLoaderRaw found 60 images\t\n",
      "\n",
      "constructing clones inside the LanguageModel\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000000_392136_ablt.jpg\" vis/imgs/img1.jpg\t\n",
      "\n",
      "image 1: a group of people standing in front of a bus\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000000_392136_orig.jpg\" vis/imgs/img2.jpg\t\n",
      "\n",
      "image 2: a group of people standing in front of a bus\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000001_392136_ablt.jpg\" vis/imgs/img3.jpg\t\n",
      "\n",
      "image 3: a group of people standing in front of a bus\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000001_392136_orig.jpg\" vis/imgs/img4.jpg\t\n",
      "\n",
      "image 4: a group of people standing in front of a bus\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000002_37015_ablt.jpg\" vis/imgs/img5.jpg\t\n",
      "\n",
      "image 5: a group of people standing around a kitchen\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000002_37015_orig.jpg\" vis/imgs/img6.jpg\t\n",
      "\n",
      "image 6: a group of people standing around a kitchen\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000003_71631_ablt.jpg\" vis/imgs/img7.jpg\t\n",
      "\n",
      "image 7: a dining room table and chairs in a kitchen\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000003_71631_orig.jpg\" vis/imgs/img8.jpg\t\n",
      "\n",
      "image 8: a dining room table and chairs in a kitchen\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000004_491269_ablt.jpg\" vis/imgs/img9.jpg\t\n",
      "\n",
      "image 9: a kitchen with a refrigerator and a stove\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000004_491269_orig.jpg\" vis/imgs/img10.jpg\t\n",
      "\n",
      "image 10: a kitchen with a refrigerator and a stove\t\n",
      "\n",
      "evaluating performance... 10/-1 (0.000000)\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000005_279108_ablt.jpg\" vis/imgs/img11.jpg\t\n",
      "\n",
      "image 11: a woman and a man standing in a kitchen\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000005_279108_orig.jpg\" vis/imgs/img12.jpg\t\n",
      "\n",
      "image 12: a woman and a man standing in a kitchen\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000006_438422_ablt.jpg\" vis/imgs/img13.jpg\t\n",
      "\n",
      "image 13: a man and a woman standing next to each other\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000006_438422_orig.jpg\" vis/imgs/img14.jpg\t\n",
      "\n",
      "image 14: a woman is holding a glass of wine\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000007_485894_ablt.jpg\" vis/imgs/img15.jpg\t\n",
      "\n",
      "image 15: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000007_485894_orig.jpg\" vis/imgs/img16.jpg\t\n",
      "\n",
      "image 16: a bathroom with a sink and a toilet\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000008_299411_ablt.jpg\" vis/imgs/img17.jpg\t\n",
      "\n",
      "image 17: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000008_299411_orig.jpg\" vis/imgs/img18.jpg\t\n",
      "\n",
      "image 18: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000009_239811_ablt.jpg\" vis/imgs/img19.jpg\t\n",
      "\n",
      "image 19: a man is riding a bike on the street\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000009_239811_orig.jpg\" vis/imgs/img20.jpg\t\n",
      "\n",
      "image 20: a man is riding a bike on the street\t\n",
      "\n",
      "evaluating performance... 20/-1 (0.000000)\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000010_287541_ablt.jpg\" vis/imgs/img21.jpg\t\n",
      "\n",
      "image 21: a bathroom with a sink and a mirror\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000010_287541_orig.jpg\" vis/imgs/img22.jpg\t\n",
      "\n",
      "image 22: a bathroom with a sink and a mirror\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000011_540162_ablt.jpg\" vis/imgs/img23.jpg\t\n",
      "\n",
      "image 23: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000011_540162_orig.jpg\" vis/imgs/img24.jpg\t\n",
      "\n",
      "image 24: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000012_357684_ablt.jpg\" vis/imgs/img25.jpg\t\n",
      "\n",
      "image 25: a group of people standing around a clock tower\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000012_357684_orig.jpg\" vis/imgs/img26.jpg\t\n",
      "\n",
      "image 26: a group of people walking down a street\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000013_576757_ablt.jpg\" vis/imgs/img27.jpg\t\n",
      "\n",
      "image 27: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000013_576757_orig.jpg\" vis/imgs/img28.jpg\t\n",
      "\n",
      "image 28: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000014_98760_ablt.jpg\" vis/imgs/img29.jpg\t\n",
      "\n",
      "image 29: a dog is looking out the window of a car\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000014_98760_orig.jpg\" vis/imgs/img30.jpg\t\n",
      "\n",
      "image 30: a dog is looking out the window of a car\t\n",
      "\n",
      "evaluating performance... 30/-1 (0.000000)\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000015_77806_ablt.jpg\" vis/imgs/img31.jpg\t\n",
      "\n",
      "image 31: a dog is sitting on a motorcycle with a helmet\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000015_77806_orig.jpg\" vis/imgs/img32.jpg\t\n",
      "\n",
      "image 32: a dog is sitting on a motorcycle with a helmet\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000016_280980_ablt.jpg\" vis/imgs/img33.jpg\t\n",
      "\n",
      "image 33: a man standing in front of a toilet in a bathroom\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000016_280980_orig.jpg\" vis/imgs/img34.jpg\t\n",
      "\n",
      "image 34: a man is standing in a bathroom with a toilet\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000017_62604_ablt.jpg\" vis/imgs/img35.jpg\t\n",
      "\n",
      "image 35: a large building with a clock on the front\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000017_62604_orig.jpg\" vis/imgs/img36.jpg\t\n",
      "\n",
      "image 36: a large building with a clock on the front\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000018_217306_ablt.jpg\" vis/imgs/img37.jpg\t\n",
      "\n",
      "image 37: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000018_217306_orig.jpg\" vis/imgs/img38.jpg\t\n",
      "\n",
      "image 38: a bathroom with a toilet and a sink\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000019_374114_ablt.jpg\" vis/imgs/img39.jpg\t\n",
      "\n",
      "image 39: a man standing in front of a train\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000019_374114_orig.jpg\" vis/imgs/img40.jpg\t\n",
      "\n",
      "image 40: a man standing in front of a train\t\n",
      "\n",
      "evaluating performance... 40/-1 (0.000000)\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000020_560459_ablt.jpg\" vis/imgs/img41.jpg\t\n",
      "\n",
      "image 41: a plane sitting on the tarmac at an airport\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000020_560459_orig.jpg\" vis/imgs/img42.jpg\t\n",
      "\n",
      "image 42: an airplane is parked on the runway at the airport\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000021_448698_ablt.jpg\" vis/imgs/img43.jpg\t\n",
      "\n",
      "image 43: a small airplane sitting on top of a field\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000021_448698_orig.jpg\" vis/imgs/img44.jpg\t\n",
      "\n",
      "image 44: a small airplane sitting on top of a field\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000022_70868_ablt.jpg\" vis/imgs/img45.jpg\t\n",
      "\n",
      "image 45: a large airplane flying over a city street\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000022_70868_orig.jpg\" vis/imgs/img46.jpg\t\n",
      "\n",
      "image 46: an airplane is parked on the runway at the airport\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000023_513541_ablt.jpg\" vis/imgs/img47.jpg\t\n",
      "\n",
      "image 47: a small airplane sitting on top of a runway\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000023_513541_orig.jpg\" vis/imgs/img48.jpg\t\n",
      "\n",
      "image 48: a small airplane sitting on top of a runway\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000024_239728_ablt.jpg\" vis/imgs/img49.jpg\t\n",
      "\n",
      "image 49: a herd of sheep grazing on a lush green field\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000024_239728_orig.jpg\" vis/imgs/img50.jpg\t\n",
      "\n",
      "image 50: a herd of sheep grazing on a lush green field\t\n",
      "\n",
      "evaluating performance... 50/-1 (0.000000)\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000025_474882_ablt.jpg\" vis/imgs/img51.jpg\t\n",
      "\n",
      "image 51: a small airplane sitting on top of a runway\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000025_474882_orig.jpg\" vis/imgs/img52.jpg\t\n",
      "\n",
      "image 52: a small airplane sitting on top of a runway\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000026_483008_ablt.jpg\" vis/imgs/img53.jpg\t\n",
      "\n",
      "image 53: a little girl sitting on a bench with a cell phone\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000026_483008_orig.jpg\" vis/imgs/img54.jpg\t\n",
      "\n",
      "image 54: a little girl is sitting on a bench\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000027_424102_ablt.jpg\" vis/imgs/img55.jpg\t\n",
      "\n",
      "image 55: a man standing in a field flying a kite\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000027_424102_orig.jpg\" vis/imgs/img56.jpg\t\n",
      "\n",
      "image 56: a man standing on top of a plane flying in the air\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000028_77375_ablt.jpg\" vis/imgs/img57.jpg\t\n",
      "\n",
      "image 57: a car parked in a parking lot next to a car\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000028_77375_orig.jpg\" vis/imgs/img58.jpg\t\n",
      "\n",
      "image 58: a car is parked in a parking lot\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000029_212091_ablt.jpg\" vis/imgs/img59.jpg\t\n",
      "\n",
      "image 59: a group of people walking down a street\t\n",
      "\n",
      "cp \"/Users/Grendel/Desktop/ML/textmatters/tmp_poking_blackout/0000000000000029_212091_orig.jpg\" vis/imgs/img60.jpg\t\n",
      "\n",
      "image 60: a group of people walking down a street\t\n",
      "\n",
      "evaluating performance... 0/-1 (0.000000)\t\n",
      "\n",
      "loss: \tnan\t\n",
      "\n",
      "Exiting with 0\n",
      "Saving results to /Users/Grendel/Desktop/ML/textmatters/output\n",
      "\n",
      "Total:\t30;\t\tMean:\t\t0.776893;\tNonezero:\t30\n",
      "Median:\t1.000000;\tMedian(H):\t1.000000;\tMedian(L):\t1.000000;\n",
      "Max:\t1.000000;\tMin:\t\t0.090909;\tStd:\t\t0.328339\n",
      "\n",
      "\n",
      "[22]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0909090909091;\tImageId:70868\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\tan airplane is parked on the runway at the airport;\n",
      "\tAblation Caption:\n",
      "\t\ta large airplane flying over a city street;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A large jetliner taking off from a runway.\n",
      "\n",
      "\t\t2. White airliner taking off from a runway with a huge cliff beside it.\n",
      "\n",
      "\t\t3. A plan rests in a small airport situated near a mountain.\n",
      "\n",
      "\t\t4. A plain on a runway in front of a mountain.\n",
      "\n",
      "\t\t5. A large airplane is taking off from a runway.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/70868\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_poking_blackout/0000000000000022_70868_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.111111111111;\tImageId:560459\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\tan airplane is parked on the runway at the airport;\n",
      "\tAblation Caption:\n",
      "\t\ta plane sitting on the tarmac at an airport;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A \"\"LAN\" Brand airplane at an airport near the sea.\n",
      "\n",
      "\t\t2. A jetliner taking off from an airport runway.\n",
      "\n",
      "\t\t3. There is a plane taxiing on the ruwnay\n",
      "\n",
      "\t\t4. A large passenger jet on an airport runway near the coast.\n",
      "\n",
      "\t\t5. A passenger jet that is on a runway.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/560459\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_poking_blackout/0000000000000020_560459_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.2;\tImageId:438422\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta woman is holding a glass of wine;\n",
      "\tAblation Caption:\n",
      "\t\ta man and a woman standing next to each other;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A woman giving a taste test to a man.\n",
      "\n",
      "\t\t2. A woman feeds a sample of her dish to a man in front of onlookers.\n",
      "\n",
      "\t\t3. Man is fed a spoonful of food by a woman in front of other people.\n",
      "\n",
      "\t\t4. Several people observing a woman feeding a man food inside a restaurant kitchen\n",
      "\n",
      "\t\t5. A woman is giving a taste of her food to a man\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/438422\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_poking_blackout/0000000000000006_438422_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IN_FILE_NAME  = 'poking.pkl'\n",
    "OUT_FILE_NAME = 'poking_blackout'\n",
    "\n",
    "pipeline.makePickle(IN_FILE_NAME, [392136] + selected_ids)\n",
    "pipeline.run(amode='blackout', input_file=IN_FILE_NAME, output_file=OUT_FILE_NAME, tmp_path='tmp_%s'%OUT_FILE_NAME, batch_size=10)\n",
    "get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME)\n",
    "\n",
    "in_ids  = cPickle.load(open(os.path.join(IN_DIR, IN_FILE_NAME)))\n",
    "scores  = cPickle.load(open(os.path.join(OUT_DIR, \"scores_%s.pkl\"%OUT_FILE_NAME)))\n",
    "vis     = json.load(open(os.path.join(OUT_DIR, 'vis_%s.json'%OUT_FILE_NAME)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'caption': u'a group of people standing in front of a bus',\n",
       "  u'image_id': u'1'},\n",
       " {u'caption': u'a group of people standing in front of a bus',\n",
       "  u'image_id': u'2'},\n",
       " {u'caption': u'a group of people standing in front of a bus',\n",
       "  u'image_id': u'3'},\n",
       " {u'caption': u'a group of people standing in front of a bus',\n",
       "  u'image_id': u'4'},\n",
       " {u'caption': u'a group of people standing around a kitchen',\n",
       "  u'image_id': u'5'},\n",
       " {u'caption': u'a group of people standing around a kitchen',\n",
       "  u'image_id': u'6'},\n",
       " {u'caption': u'a dining room table and chairs in a kitchen',\n",
       "  u'image_id': u'7'},\n",
       " {u'caption': u'a dining room table and chairs in a kitchen',\n",
       "  u'image_id': u'8'},\n",
       " {u'caption': u'a kitchen with a refrigerator and a stove', u'image_id': u'9'},\n",
       " {u'caption': u'a kitchen with a refrigerator and a stove',\n",
       "  u'image_id': u'10'},\n",
       " {u'caption': u'a woman and a man standing in a kitchen', u'image_id': u'11'},\n",
       " {u'caption': u'a woman and a man standing in a kitchen', u'image_id': u'12'},\n",
       " {u'caption': u'a man and a woman standing next to each other',\n",
       "  u'image_id': u'13'},\n",
       " {u'caption': u'a woman is holding a glass of wine', u'image_id': u'14'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'15'},\n",
       " {u'caption': u'a bathroom with a sink and a toilet', u'image_id': u'16'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'17'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'18'},\n",
       " {u'caption': u'a man is riding a bike on the street', u'image_id': u'19'},\n",
       " {u'caption': u'a man is riding a bike on the street', u'image_id': u'20'},\n",
       " {u'caption': u'a bathroom with a sink and a mirror', u'image_id': u'21'},\n",
       " {u'caption': u'a bathroom with a sink and a mirror', u'image_id': u'22'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'23'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'24'},\n",
       " {u'caption': u'a group of people standing around a clock tower',\n",
       "  u'image_id': u'25'},\n",
       " {u'caption': u'a group of people walking down a street', u'image_id': u'26'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'27'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'28'},\n",
       " {u'caption': u'a dog is looking out the window of a car', u'image_id': u'29'},\n",
       " {u'caption': u'a dog is looking out the window of a car', u'image_id': u'30'},\n",
       " {u'caption': u'a dog is sitting on a motorcycle with a helmet',\n",
       "  u'image_id': u'31'},\n",
       " {u'caption': u'a dog is sitting on a motorcycle with a helmet',\n",
       "  u'image_id': u'32'},\n",
       " {u'caption': u'a man standing in front of a toilet in a bathroom',\n",
       "  u'image_id': u'33'},\n",
       " {u'caption': u'a man is standing in a bathroom with a toilet',\n",
       "  u'image_id': u'34'},\n",
       " {u'caption': u'a large building with a clock on the front',\n",
       "  u'image_id': u'35'},\n",
       " {u'caption': u'a large building with a clock on the front',\n",
       "  u'image_id': u'36'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'37'},\n",
       " {u'caption': u'a bathroom with a toilet and a sink', u'image_id': u'38'},\n",
       " {u'caption': u'a man standing in front of a train', u'image_id': u'39'},\n",
       " {u'caption': u'a man standing in front of a train', u'image_id': u'40'},\n",
       " {u'caption': u'a plane sitting on the tarmac at an airport',\n",
       "  u'image_id': u'41'},\n",
       " {u'caption': u'an airplane is parked on the runway at the airport',\n",
       "  u'image_id': u'42'},\n",
       " {u'caption': u'a small airplane sitting on top of a field',\n",
       "  u'image_id': u'43'},\n",
       " {u'caption': u'a small airplane sitting on top of a field',\n",
       "  u'image_id': u'44'},\n",
       " {u'caption': u'a large airplane flying over a city street',\n",
       "  u'image_id': u'45'},\n",
       " {u'caption': u'an airplane is parked on the runway at the airport',\n",
       "  u'image_id': u'46'},\n",
       " {u'caption': u'a small airplane sitting on top of a runway',\n",
       "  u'image_id': u'47'},\n",
       " {u'caption': u'a small airplane sitting on top of a runway',\n",
       "  u'image_id': u'48'},\n",
       " {u'caption': u'a herd of sheep grazing on a lush green field',\n",
       "  u'image_id': u'49'},\n",
       " {u'caption': u'a herd of sheep grazing on a lush green field',\n",
       "  u'image_id': u'50'},\n",
       " {u'caption': u'a small airplane sitting on top of a runway',\n",
       "  u'image_id': u'51'},\n",
       " {u'caption': u'a small airplane sitting on top of a runway',\n",
       "  u'image_id': u'52'},\n",
       " {u'caption': u'a little girl sitting on a bench with a cell phone',\n",
       "  u'image_id': u'53'},\n",
       " {u'caption': u'a little girl is sitting on a bench', u'image_id': u'54'},\n",
       " {u'caption': u'a man standing in a field flying a kite', u'image_id': u'55'},\n",
       " {u'caption': u'a man standing on top of a plane flying in the air',\n",
       "  u'image_id': u'56'},\n",
       " {u'caption': u'a car parked in a parking lot next to a car',\n",
       "  u'image_id': u'57'},\n",
       " {u'caption': u'a car is parked in a parking lot', u'image_id': u'58'},\n",
       " {u'caption': u'a group of people walking down a street', u'image_id': u'59'},\n",
       " {u'caption': u'a group of people walking down a street', u'image_id': u'60'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'caption': u'a man standing in front of a truck', u'image_id': u'7'},\n",
       " {u'caption': u'a lunch box with a variety of food', u'image_id': u'8'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_FILE_NAME  = \"rel_texts_img_ids.pkl\"\n",
    "OUT_FILE_NAME = \"rel_texts_gaussian\"\n",
    "in_ids  = cPickle.load(open(os.path.join(IN_DIR, IN_FILE_NAME)))\n",
    "scores  = cPickle.load(open(os.path.join(OUT_DIR, \"scores_%s.pkl\"%OUT_FILE_NAME)))\n",
    "vis     = json.load(open(os.path.join(OUT_DIR, 'vis_%s.json'%OUT_FILE_NAME)))\n",
    "len(vis), len(scores), len(in_ids)\n",
    "start = 3\n",
    "vis[start*2:start*2+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
