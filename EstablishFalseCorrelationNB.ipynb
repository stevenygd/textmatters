{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=15.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "CWD = %pwd\n",
    "CWD = str(CWD)\n",
    "import sys\n",
    "import json\n",
    "from six.moves import cPickle\n",
    "import os\n",
    "import statistics\n",
    "from collections import defaultdict,Iterable\n",
    "\n",
    "from IPython.core.display import HTML \n",
    "from IPython.core.display import Image, display, display_pretty\n",
    "\n",
    "import numpy as np\n",
    "from scipy import misc, polyfit, stats\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "# from PIL import Image\n",
    "%matplotlib inline  \n",
    "import re\n",
    "\n",
    "COCO_PATH = os.path.join(CWD,'data','coco')\n",
    "COCO_ANNO_PATH = os.path.join(COCO_PATH, 'annotations')\n",
    "sys.path.insert(0, os.path.join(CWD, 'coco', 'PythonAPI'))\n",
    "from pycocotools.coco import COCO,mask\n",
    "coco = COCO(os.path.join(COCO_ANNO_PATH,'instances_train2014.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Coco data\n",
    "\"\"\"\n",
    "\n",
    "# load the data from captions\n",
    "with open(COCO_ANNO_PATH + '/captions_train2014.json') as f:\n",
    "    coco_captions = json.load(f)\n",
    "# print len(coco_captions)\n",
    "# with open(COCO_ANNO_PATH + 'captions_val2014.json') as f:\n",
    "#     coco_captions =  dict(coco_captions.items() + json.load(f).items())\n",
    "# print len(coco_captions)\n",
    "\n",
    "# build the reverse dictionary, from img_id to captions, img_infos, and annotations\n",
    "img_captions = {}\n",
    "for img_info in coco_captions['images']:\n",
    "    mid = str(img_info['id'])\n",
    "    if not mid in img_captions:\n",
    "        img_captions[mid] = {}\n",
    "    img_captions[mid]['image'] = img_info\n",
    "\n",
    "for cap_info in coco_captions['annotations']:\n",
    "    mid = str(cap_info['image_id'])\n",
    "    if not 'annotation' in img_captions[mid]:\n",
    "        img_captions[mid]['annotation'] = []\n",
    "        img_captions[mid]['captions'] = []\n",
    "    img_captions[mid]['annotation'].append(cap_info)\n",
    "    img_captions[mid]['captions'].append(cap_info['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl:22653\n",
      "Filtered:7839\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = [x.upper() for x in stopwords.words('english')]\n",
    "\n",
    "caps = [ c.replace(\".\",\" \").replace(\",\",\" \").upper() for _,x in img_captions.iteritems() for c in x['captions']]\n",
    "break_words = \" \".join(caps).split(\" \")\n",
    "all_words = list(set([x for x in break_words if x.isalnum() and x not in sw]))\n",
    "assert(len(all_words) < 22775)\n",
    "print \"Origianl:%d\"%len(all_words)\n",
    "\n",
    "# Filter out the words that appears less than 5 times\n",
    "from collections import Counter\n",
    "freq_map = Counter(break_words)\n",
    "all_words = [w for w in all_words if freq_map[w] > 5]\n",
    "print(\"Filtered:%d\"%len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_idx = {}\n",
    "for idx in range(len(all_words)):\n",
    "    word_idx[all_words[idx]] = idx\n",
    "assert(len(word_idx) == len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Count word_idx -> frequency\n",
    "2. Count word_idx_1, word_idx_2 -> coexistence frequency\n",
    "3. Compute conditional probablity: (coexistence frenquency)/(word frequency)\n",
    "\"\"\"\n",
    "freq   = np.zeros(len(all_words),                   dtype=np.float64)\n",
    "comatx = np.zeros((len(all_words), len(all_words)), dtype=np.float64)\n",
    "for _, data in img_captions.iteritems():\n",
    "    for cap in data['captions']:\n",
    "        # get all the word ides\n",
    "        cap = cap.replace(\".\",\" \").replace(\",\",\" \").upper()\n",
    "        cap_words = [x for x in cap.split(\" \") if x.isalnum() and x not in sw and x in word_idx]\n",
    "        cap_words_idx = set([word_idx[x] for x in cap_words])\n",
    "        \n",
    "        # increment frequency map\n",
    "        for widx in cap_words_idx:\n",
    "            freq[widx] += 1\n",
    "            \n",
    "        # increment coexistence map\n",
    "        for widx in cap_words_idx:\n",
    "            for vidx in cap_words_idx:\n",
    "                comatx[widx,vidx] += 1\n",
    "            \n",
    "prob_mat = comatx / freq\n",
    "\n",
    "assert(np.allclose(np.diagonal(prob_mat), np.ones(len(all_words))))\n",
    "assert(len(freq[freq>0]) == len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000786281409976 2324566.0 13929982.0 0.000786281409976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1082220593904426e-06"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cond_prob(w1, given = None):\n",
    "    if given == None: return 1\n",
    "    w1idx = word_idx[w1.upper()]\n",
    "    w2idx = word_idx[given.upper()]\n",
    "    return prob_mat[w1idx, w2idx]\n",
    "\n",
    "# high_cond_prob = [x for x in all_words for y in all_words if x != y and cond_prob(x,given=y) > 0.8]\n",
    "# len(high_cond_prob)\n",
    "print np.mean(prob_mat), np.sum(freq), np.sum(comatx), np.mean(prob_mat)\n",
    "# print len(prob_mat[prob_mat>0.0])\n",
    "(len(prob_mat[prob_mat > 0.9]) - len(all_words))*1.0/(len(all_words)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYBOARD ERGONOMIC\n",
      "1.0 0.00382775119617\n",
      "2090.0 8.0\n"
     ]
    }
   ],
   "source": [
    "idxes = np.where(prob_mat>0.90)\n",
    "import random\n",
    "while True:\n",
    "    k = random.randint(0, len(idxes[0]))\n",
    "    x, y = idxes[0][k], idxes[1][k]\n",
    "    if x == y: continue\n",
    "    x, y = all_words[x], all_words[y]\n",
    "    print x, y\n",
    "    print cond_prob(x, given = y), cond_prob(y, given = x)\n",
    "    print freq[word_idx[x.upper()]], freq[word_idx[y.upper()]]\n",
    "    break\n",
    "\n",
    "# print cond_prob(\"winnie\", given = \"pooh\")\n",
    "# print cond_prob(\"red\", given = \"rose\"), cond_prob(\"rose\", given = \"red\")\n",
    "# # all_words[10]\n",
    "# print freq[word_idx['winnie'.upper()]], freq[word_idx['pooh'.upper()]]\n",
    "# print freq[word_idx['red'.upper()]],    freq[word_idx['rose'.upper()]]\n",
    "# print comatx[word_idx['RED'], word_idx['ROSE']], comatx[word_idx['ROSE'], word_idx['RED']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "N = len(all_words)\n",
    "prob_mat_not_sym = (np.ones((N,N)) - np.diag(np.ones(N))) * prob_mat\n",
    "ones_idx = np.where(prob_mat_not_sym > 0.9)\n",
    "print len(ones_idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "def wanted(x,y):\n",
    "    return not (freq[y] / freq[x] > 100 or freq[x] / freq[y] > 100 or freq[y] < 10 or freq[x] < 10)\n",
    "clean_idx = [(x,y) for x,y in zip(ones_idx[0], ones_idx[1]) if wanted(x,y)]\n",
    "print len(clean_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 7588\n",
      "MOUSE MICKEY 1130.0 21.0\n",
      "0.952380952381 0.0176991150442\n",
      "167 4151\n",
      "LIT DIMLY 987.0 154.0\n",
      "0.961038961039 0.149949341439\n",
      "457 4\n",
      "POOH WINNIE 14.0 11.0\n",
      "1.0 0.785714285714\n",
      "468 2240\n",
      "TENNIS RACKETS 11224.0 440.0\n",
      "0.920454545455 0.0360833927299\n",
      "468 2635\n",
      "TENNIS RACKET 11224.0 3102.0\n",
      "0.930689877498 0.257216678546\n",
      "468 6636\n",
      "TENNIS COURT 11224.0 4320.0\n",
      "0.938194444444 0.361101211689\n",
      "468 7479\n",
      "TENNIS RACQUET 11224.0 1553.0\n",
      "0.938184159691 0.129811119031\n",
      "624 3583\n",
      "TATER TOTS 17.0 15.0\n",
      "1.0 0.882352941176\n",
      "716 3084\n",
      "ROOM LIVING 12730.0 5420.0\n",
      "0.935793357934 0.398428908091\n",
      "723 5006\n",
      "WIND INDICATOR 237.0 12.0\n",
      "0.916666666667 0.0464135021097\n",
      "792 6906\n",
      "WEATHER VEIN 144.0 10.0\n",
      "1.0 0.0694444444444\n",
      "792 7730\n",
      "WEATHER VANE 144.0 37.0\n",
      "0.945945945946 0.243055555556\n",
      "1083 5337\n",
      "PING PONG 28.0 29.0\n",
      "0.965517241379 1.0\n",
      "1118 3769\n",
      "IRON WROUGHT 167.0 26.0\n",
      "1.0 0.155688622754\n",
      "1413 6082\n",
      "IMAGE UNABLE 2781.0 58.0\n",
      "0.948275862069 0.019777058612\n",
      "1483 5217\n",
      "WHEEL FERRIS 242.0 17.0\n",
      "1.0 0.0702479338843\n",
      "1738 365\n",
      "KRISPY KREME 43.0 40.0\n",
      "0.95 0.883720930233\n",
      "1753 5227\n",
      "LEGS HIND 531.0 71.0\n",
      "0.915492957746 0.122410546139\n",
      "1858 2739\n",
      "WINDOW SILL 5105.0 265.0\n",
      "0.977358490566 0.0507345739471\n",
      "1971 944\n",
      "DOUBLE DECKER 2175.0 1568.0\n",
      "0.989158163265 0.713103448276\n",
      "1971 2679\n",
      "DOUBLE DECKERED 2175.0 40.0\n",
      "1.0 0.0183908045977\n",
      "2003 7013\n",
      "BED UNMADE 8072.0 178.0\n",
      "0.932584269663 0.0205649157582\n",
      "2088 3431\n",
      "ROMAN NUMERAL 85.0 30.0\n",
      "0.966666666667 0.341176470588\n",
      "2088 7309\n",
      "ROMAN NUMERALS 85.0 47.0\n",
      "0.957446808511 0.529411764706\n",
      "2103 4094\n",
      "SLAW COLE 43.0 35.0\n",
      "0.971428571429 0.790697674419\n",
      "2244 3378\n",
      "KNACKS KNICK 34.0 31.0\n",
      "0.967741935484 0.882352941176\n",
      "2553 5748\n",
      "BRIDGE SUSPENSION 1265.0 13.0\n",
      "0.923076923077 0.00948616600791\n",
      "2564 4415\n",
      "ANGELES LOS 14.0 14.0\n",
      "0.928571428571 0.928571428571\n",
      "2829 5622\n",
      "SHOWER STANDUP 1569.0 28.0\n",
      "0.928571428571 0.0165710643722\n",
      "2905 7736\n",
      "GREEN LUSH 8615.0 1005.0\n",
      "0.930348258706 0.108531630876\n",
      "2965 1651\n",
      "MOTOR CYCLE 791.0 146.0\n",
      "0.904109589041 0.166877370417\n",
      "2993 3697\n",
      "FED EX 92.0 13.0\n",
      "0.923076923077 0.130434782609\n",
      "3113 1153\n",
      "HARLEY DAVIDSON 29.0 23.0\n",
      "1.0 0.793103448276\n",
      "3260 2565\n",
      "CREAM WHIPPED 526.0 78.0\n",
      "0.910256410256 0.134980988593\n",
      "3490 4400\n",
      "TIME ZONES 823.0 13.0\n",
      "0.923076923077 0.0145808019441\n",
      "3490 6057\n",
      "TIME LAPSE 823.0 37.0\n",
      "1.0 0.044957472661\n",
      "3611 6082\n",
      "SEE UNABLE 406.0 58.0\n",
      "0.965517241379 0.137931034483\n",
      "3656 7567\n",
      "WAR II 103.0 11.0\n",
      "1.0 0.106796116505\n",
      "3732 2074\n",
      "RUBBER DUCKY 70.0 11.0\n",
      "1.0 0.157142857143\n",
      "3765 5526\n",
      "SPROUTS BRUSSEL 45.0 16.0\n",
      "1.0 0.355555555556\n",
      "3930 630\n",
      "WII MOTES 2401.0 29.0\n",
      "1.0 0.012078300708\n",
      "3930 2019\n",
      "WII MOTE 2401.0 52.0\n",
      "0.980769230769 0.021241149521\n",
      "3930 2233\n",
      "WII NINTENDO 2401.0 741.0\n",
      "0.968960863698 0.299042065806\n",
      "3932 7463\n",
      "WIT HA 114.0 80.0\n",
      "0.925 0.649122807018\n",
      "4095 2704\n",
      "COLA COCA 61.0 37.0\n",
      "0.972972972973 0.590163934426\n",
      "4200 2749\n",
      "AIR FORCE 5288.0 98.0\n",
      "0.938775510204 0.017397881997\n",
      "4271 4249\n",
      "NEW YORK 376.0 54.0\n",
      "0.981481481481 0.140957446809\n",
      "4299 7151\n",
      "POINT FOCAL 132.0 17.0\n",
      "0.941176470588 0.121212121212\n",
      "4415 2564\n",
      "LOS ANGELES 14.0 14.0\n",
      "0.928571428571 0.928571428571\n",
      "4432 973\n",
      "HORSE JOCKEY 5654.0 121.0\n",
      "0.925619834711 0.0198089847895\n",
      "4490 5285\n",
      "BRIDE GROOM 220.0 197.0\n",
      "0.954314720812 0.854545454545\n",
      "4647 1286\n",
      "MARKET FLEA 970.0 15.0\n",
      "1.0 0.0154639175258\n",
      "4671 1395\n",
      "CAT TABBY 11447.0 172.0\n",
      "0.906976744186 0.01362802481\n",
      "4680 7048\n",
      "MAKE SHIFT 339.0 12.0\n",
      "1.0 0.0353982300885\n",
      "4743 7738\n",
      "FLIP FLOPS 206.0 12.0\n",
      "1.0 0.0582524271845\n",
      "4968 928\n",
      "LAMP LAVA 740.0 15.0\n",
      "0.933333333333 0.0189189189189\n",
      "4991 2697\n",
      "CORN COB 172.0 23.0\n",
      "1.0 0.133720930233\n",
      "4996 3175\n",
      "WIRE BARB 515.0 17.0\n",
      "0.941176470588 0.031067961165\n",
      "4996 6210\n",
      "WIRE BARBED 515.0 89.0\n",
      "0.966292134831 0.166990291262\n",
      "5337 1083\n",
      "PONG PING 29.0 28.0\n",
      "1.0 0.965517241379\n",
      "5417 3889\n",
      "BREAD LOAVES 1134.0 14.0\n",
      "1.0 0.0123456790123\n",
      "5719 4575\n",
      "HAIR COMBING 1047.0 32.0\n",
      "0.96875 0.0296084049666\n",
      "5766 1931\n",
      "PARKING METERS 3090.0 270.0\n",
      "0.944444444444 0.0825242718447\n",
      "5766 6329\n",
      "PARKING METER 3090.0 981.0\n",
      "0.907237512742 0.288025889968\n",
      "5891 5261\n",
      "BANANAS UNRIPE 2969.0 62.0\n",
      "0.935483870968 0.019535197036\n",
      "6263 1447\n",
      "STAR WARS 83.0 12.0\n",
      "1.0 0.144578313253\n",
      "6273 2001\n",
      "BIG BEN 3771.0 182.0\n",
      "0.978021978022 0.0472023335985\n",
      "6477 4411\n",
      "SANTA CLAUS 165.0 32.0\n",
      "1.0 0.193939393939\n",
      "6477 6026\n",
      "SANTA CLAUSE 165.0 22.0\n",
      "1.0 0.133333333333\n",
      "6589 3696\n",
      "FIRE HYDRANTS 4352.0 47.0\n",
      "0.978723404255 0.0105698529412\n",
      "6589 4462\n",
      "FIRE HYDRANT 4352.0 3602.0\n",
      "0.958356468629 0.793198529412\n",
      "6625 6125\n",
      "BUTTER PEANUT 179.0 95.0\n",
      "0.915789473684 0.486033519553\n",
      "6805 6727\n",
      "BEEF CORNED 193.0 11.0\n",
      "1.0 0.0569948186528\n",
      "6904 7567\n",
      "WORLD II 86.0 11.0\n",
      "1.0 0.127906976744\n",
      "7061 5668\n",
      "HAY BALE 523.0 14.0\n",
      "0.928571428571 0.0248565965583\n",
      "7061 7098\n",
      "HAY BALES 523.0 15.0\n",
      "0.933333333333 0.0267686424474\n",
      "7146 4749\n",
      "CHAIN LINKED 212.0 17.0\n",
      "0.941176470588 0.0754716981132\n",
      "7146 7641\n",
      "CHAIN LINK 212.0 95.0\n",
      "0.957894736842 0.429245283019\n",
      "7267 5109\n",
      "CLOCK ALARM 6734.0 71.0\n",
      "0.929577464789 0.00980100980101\n",
      "7267 7675\n",
      "CLOCK GRANDFATHER 6734.0 85.0\n",
      "0.917647058824 0.011583011583\n",
      "7382 3112\n",
      "SAN FRANCISCO 26.0 18.0\n",
      "1.0 0.692307692308\n",
      "7447 1644\n",
      "PIZZA PEPPERONI 8410.0 353.0\n",
      "0.968838526912 0.0406658739596\n",
      "7589 2221\n",
      "EYES GOOGLY 427.0 10.0\n",
      "1.0 0.0234192037471\n",
      "7723 7219\n",
      "LAW ENFORCEMENT 24.0 13.0\n",
      "0.923076923077 0.5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# idx = random.randint(0, len(clean_idx[0]));\n",
    "for idx in range(len(clean_idx)):\n",
    "    x, y = clean_idx[idx]\n",
    "    print x, y\n",
    "    print all_words[x], all_words[y], freq[x], freq[y]\n",
    "    print cond_prob(all_words[x], given=all_words[y]), cond_prob(all_words[y], given=all_words[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'TOILET', u'SINK', u'WHITE', u'MIRROR', u'SHOWER', u'SMALL', u'TUB', u'SITTING', u'NEXT', u'WALL']\n"
     ]
    }
   ],
   "source": [
    "def most_prob_words(word, num = 10):\n",
    "    idxes = np.argsort(prob_mat[:,word_idx[word.upper()]])\n",
    "    words = [all_words[idx] for idx in idxes[-2:-num-2:-1]]\n",
    "#     words = [idx for idx in idxes[:-num-1:-1]]\n",
    "    return words\n",
    "\n",
    "print most_prob_words('bathroom')\n",
    "\n",
    "assert 1.0 == prob_mat[k,k], k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'person', u'bicycle', u'car', u'motorcycle', u'airplane', u'bus', u'train', u'truck', u'boat', u'traffic light', u'fire hydrant', u'stop sign', u'parking meter', u'bench', u'bird', u'cat', u'dog', u'horse', u'sheep', u'cow', u'elephant', u'bear', u'zebra', u'giraffe', u'backpack', u'umbrella', u'handbag', u'tie', u'suitcase', u'frisbee', u'skis', u'snowboard', u'sports ball', u'kite', u'baseball bat', u'baseball glove', u'skateboard', u'surfboard', u'tennis racket', u'bottle', u'wine glass', u'cup', u'fork', u'knife', u'spoon', u'bowl', u'banana', u'apple', u'sandwich', u'orange', u'broccoli', u'carrot', u'hot dog', u'pizza', u'donut', u'cake', u'chair', u'couch', u'potted plant', u'bed', u'dining table', u'toilet', u'tv', u'laptop', u'mouse', u'remote', u'keyboard', u'cell phone', u'microwave', u'oven', u'toaster', u'sink', u'refrigerator', u'book', u'clock', u'vase', u'scissors', u'teddy bear', u'hair drier', u'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "all_info = json.load(open(os.path.join(COCO_ANNO_PATH, 'image_info_test2014.json')))\n",
    "category_names = [x['name'] for x in all_info['categories']]\n",
    "categories = {x['name']:{} for x in all_info['categories']}\n",
    "for cate, d in categories.iteritems():\n",
    "    for word in cate.split(\" \"):\n",
    "        d.update({ word : most_prob_words(word)})\n",
    "print category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'refrigerator': [u'KITCHEN',\n",
       "  u'WHITE',\n",
       "  u'STOVE',\n",
       "  u'OPEN',\n",
       "  u'NEXT',\n",
       "  u'SITTING',\n",
       "  u'DOOR',\n",
       "  u'SINK',\n",
       "  u'MICROWAVE',\n",
       "  u'SMALL']}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[category_names[random.randint(0, len(category_names))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Helper functions to save/load csr matrix\"\"\"\n",
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.csc_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_sparse_csr(os.path.join(CWD,'stats','cond_prob','prob_mat_filtered.npz'),scipy.sparse.csc_matrix(prob_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(CWD,'stats','cond_prob','freq_filtered.npz'),'w+') as f:\n",
    "    np.save(f, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_sparse_csr(os.path.join(CWD,'stats','cond_prob','comatx_filtered.npz'),scipy.sparse.csc_matrix(comatx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(CWD,'stats','cond_prob','words_and_rvwords_filtered.pkl'),'w+') as f:\n",
    "    cPickle.dump(all_words, f, protocol=cPickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For experiments, load the numbers and start from here.\n",
    "### Do not try to run above cells again. Will take forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7839 7839\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load numbers\"\"\"\n",
    "prob_mat = load_sparse_csr(os.path.join(CWD,'stats','cond_prob','prob_mat_filtered.npz')).todense()\n",
    "freq = np.load(os.path.join(CWD,'stats','cond_prob','freq_filtered.npz'))\n",
    "comatx = load_sparse_csr(os.path.join(CWD,'stats','cond_prob','comatx_filtered.npz')).todense()\n",
    "with open(os.path.join(CWD,'stats','cond_prob','words_and_rvwords_filtered.pkl'),'r') as f:\n",
    "    all_words = cPickle.load(f)\n",
    "print len(all_words), len(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toilet category experiments with median background filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134 1134\n"
     ]
    }
   ],
   "source": [
    "#load results\n",
    "with open(os.path.join(CWD, 'stats','toilet_median_bg', 'toilet_no_sink_median_bg_71.pkl')) as f:\n",
    "    d = cPickle.load(f)\n",
    "ablts = [x['ablt'].upper() for _,x in d.iteritems() if isinstance(x,dict)]\n",
    "origs = [x['orig'].upper() for _,x in d.iteritems() if isinstance(x,dict)]\n",
    "print len(ablts), len(origs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'BATHROOM', u'SINK', u'WHITE', u'SITTING', u'NEXT']\n",
      "966 1135\n"
     ]
    }
   ],
   "source": [
    "def count_cate_high_coexist_words(cate, d):\n",
    "    \"\"\"count the number of images in the category that have the 5 words with highest probability\n",
    "    occuring in the ablated captions.\n",
    "    [arg] d - captioning results. imgid -> 'score', 'ablt', 'orig' \n",
    "          cate - str\n",
    "    \"\"\"\n",
    "    hfwords = most_prob_words(cate, num = 5)\n",
    "    ablts = [x['ablt'] for _,x in d.iteritems() if isinstance(x,dict)]\n",
    "    origs = [x['orig'] for _,x in d.iteritems() if isinstance(x,dict)]\n",
    "    print hfwords\n",
    "    def _judge(pair):\n",
    "        orig,ablt = pair\n",
    "        for w in hfwords:\n",
    "#             if w in ablt.upper() and w not in orig.upper():\n",
    "            if w in ablt.upper():\n",
    "                return True\n",
    "        return False\n",
    "    return len(filter(_judge, zip(origs,ablts)))\n",
    "\n",
    "print count_cate_high_coexist_words('toilet'.upper(),d), len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATHROOM\t\t0.864440078585\t0.884657236126\t0.541167988464\n",
      "SINK\t\t0.483300589391\t0.341675734494\t0.284354722422\n",
      "WHITE\t\t0.23673870334\t0.588683351469\t0.202307137707\n",
      "SITTING\t\t0.356581532417\t0.47007616975\t0.131651045422\n",
      "NEXT\t\t0.194499017682\t0.44613710555\t0.116798846431\n"
     ]
    }
   ],
   "source": [
    "def calc_cond(sentences, word, given):\n",
    "    word, given = word.upper(), given.upper()\n",
    "    both = [s for s in sentences if word in s and given in s]\n",
    "    only_given = [s for s in sentences if given in s]\n",
    "    return 1.0*len(both)/len(only_given)\n",
    "\n",
    "cate = 'toilet'\n",
    "for w in most_prob_words(cate, num = 5):\n",
    "    print \"%s\\t\\t%s\\t%s\\t%s\"%(w, calc_cond(origs, w,'toilet'), calc_cond(ablts, w,'toilet'),  cond_prob(w, 'toilet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    }
   ],
   "source": [
    "print len(set(ablts+origs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
