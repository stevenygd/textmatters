{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Experiment Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from six.moves import cPickle\n",
    "import os\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.core.display import HTML \n",
    "from IPython.core.display import Image, display, display_pretty\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Coco data\n",
    "\"\"\"\n",
    "COCO_PATH = 'data/coco/'\n",
    "COCO_ANNO_PATH = COCO_PATH + 'annotations/'\n",
    "\n",
    "# load the data from captions\n",
    "with open(COCO_ANNO_PATH + 'captions_train2014.json') as f:\n",
    "    coco_captions = json.load(f)\n",
    "# print len(coco_captions)\n",
    "# with open(COCO_ANNO_PATH + 'captions_val2014.json') as f:\n",
    "#     coco_captions =  dict(coco_captions.items() + json.load(f).items())\n",
    "# print len(coco_captions)\n",
    "\n",
    "# build the reverse dictionary, from img_id to captions, img_infos, and annotations\n",
    "img_captions = {}\n",
    "for img_info in coco_captions['images']:\n",
    "    mid = int(img_info['id'])\n",
    "    if not mid in img_captions:\n",
    "        img_captions[mid] = {}\n",
    "    img_captions[mid]['image'] = img_info\n",
    "\n",
    "for cap_info in coco_captions['annotations']:\n",
    "    mid = int(cap_info['image_id'])\n",
    "    if not 'annotation' in img_captions[mid]:\n",
    "        img_captions[mid]['annotation'] = []\n",
    "        img_captions[mid]['captions'] = []\n",
    "    img_captions[mid]['annotation'].append(cap_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IN_FILE_NAME  = 'scores_no_rel_texts_blackout.pkl'\n",
    "OUT_FILE_NAME = 'no_rel_texts_img_ids'\n",
    "IN_DIR        = 'input'\n",
    "OUT_DIR       = 'output'\n",
    "\n",
    "def pre_process_vis(vis, scores, l):\n",
    "    \"\"\"Since with large batch size, vis.json might contain duplicates. This function will purge out the duplicates.\n",
    "    l is the number of image ids used to generate vis. After filtering, vis should have length 2l.\"\"\"\n",
    "    surplus = len(vis)-2*l\n",
    "    return vis[:-surplus], scores[:-(surplus/2)]\n",
    "\n",
    "def get_stat(data):\n",
    "    if len(data)==0: return;\n",
    "    print \"\"\n",
    "    print \"Total:\\t%d;\\t\\tMean:\\t\\t%f;\\tNonezero:\\t%d\"%(len(data), statistics.mean(data), len(filter(lambda x:x!=0, data)))\n",
    "    print \"Median:\\t%f;\\tMedian(H):\\t%f;\\tMedian(L):\\t%f;\"%(statistics.median(data), statistics.median_high(data), statistics.median_low(data))\n",
    "    print \"Max:\\t%f;\\tMin:\\t\\t%f;\\tStd:\\t\\t%f\"%(max(data), min(data),statistics.stdev(data))\n",
    "    print \"\\n\"\n",
    "    \n",
    "def look_up_image(title, idx, in_ids, vis, scores, out_file):\n",
    "    print \"[%d]%s\\n\"%(idx,title)\n",
    "    print \"\\tScore:%s;\\tImageId:%s\\n\"%(scores[idx], in_ids[idx])\n",
    "    print \"\\tOriginal Caption:\\n\\t\\t%s;\\n\\tAblation Caption:\\n\\t\\t%s;\"%(vis[idx*2+1]['caption'],vis[idx*2]['caption'])\n",
    "    print \"\\tAnnotated Captions:\\n\"\n",
    "    img_id = int(in_ids[idx])\n",
    "    for i, note in enumerate(img_captions[img_id]['annotation']):\n",
    "        print \"\\t\\t%d. %s\\n\"%(i+1, str(note['caption']).strip())\n",
    "    \n",
    "    # Display images side by side: http://permalink.gmane.org/gmane.comp.python.ipython.devel/11073\n",
    "    s = \"\"\"<table>\n",
    "        <tr>\n",
    "        <th><img src=\"%s\" style=\"max-width:400px\" /></th>\n",
    "        <th><img src=\"%s\" style=\"max-width:400px\" /></th>\n",
    "        </tr></table>\"\"\"%(img_captions[img_id]['image']['coco_url'], \"%s\"%os.path.join(\"tmp_%s\"%out_file, \"%s_%s_ablt.jpg\"%(str(idx).zfill(16),str(img_id))))\n",
    "    t=HTML(s)\n",
    "    display(t)\n",
    "\n",
    "def get_expr_summary(in_file=IN_FILE_NAME, out_file=OUT_FILE_NAME, in_path=IN_DIR, out_path=OUT_DIR, num=3):\n",
    "    in_ids  = cPickle.load(open(os.path.join(in_path, in_file)))\n",
    "    scores  = cPickle.load(open(os.path.join(out_path, \"scores_%s.pkl\"%out_file)))\n",
    "    vis     = json.load(open(os.path.join(out_path, 'vis_%s.json'%out_file)))\n",
    "    vis, scores = pre_process_vis(vis, scores, len(in_ids))\n",
    "#     print \"Statistics for scores of gaussian filtered ablations:\"\n",
    "    get_stat(scores)\n",
    "\n",
    "    scores_idx = zip(range(len(scores)), scores)\n",
    "    sorted_scores_idx = sorted(scores_idx, key=lambda x: x[1])   # sort by score\n",
    "    for idx, _ in sorted_scores_idx[:num]:\n",
    "        look_up_image(\"Images with lowest scores:\",idx, in_ids, vis, scores, out_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total:\t15980;\t\tMean:\t\t0.056327;\tNonezero:\t6696\n",
      "Median:\t0.000000;\tMedian(H):\t0.000000;\tMedian(L):\t0.000000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.094948\n",
      "\n",
      "\n",
      "[0]Images with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:392136\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man with a hat and a hat on a clock;\n",
      "\tAblation Caption:\n",
      "\t\ta group of people standing next to each other;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A large bus and some people on the street.\n",
      "\n",
      "\t\t2. Several people are standing on the sidewalk as a bus goes by.\n",
      "\n",
      "\t\t3. Bus rushing by a group of people walking in a city.\n",
      "\n",
      "\t\t4. A double-decker bus moving down the street as people stand waiting.\n",
      "\n",
      "\t\t5. A group of people standing next to a yellow and blue double decker bus.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/392136\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_no_rel_texts_blackout/0000000000000000_392136_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Images with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:71631\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man and a woman standing next to each other;\n",
      "\tAblation Caption:\n",
      "\t\ta truck is parked in a parking lot;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. Dining room table set for a casual meal, with flowers.\n",
      "\n",
      "\t\t2. A red table topped with four white place mats.\n",
      "\n",
      "\t\t3. there is a dining room table with a red cloth and a vase with roses\n",
      "\n",
      "\t\t4. a table with a red tablecloth and white placemats\n",
      "\n",
      "\t\t5. A small dinning table with all red napkins and a red table cloth .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/71631\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_no_rel_texts_blackout/0000000000000002_71631_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]Images with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:279108\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta desk with a laptop and a keyboard;\n",
      "\tAblation Caption:\n",
      "\t\ta bus is driving down the street in a city;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A woman feeding a man food from a spoon.\n",
      "\n",
      "\t\t2. A woman offering a man a taste of something in front of other people.\n",
      "\n",
      "\t\t3. A woman feeds a man a bite of food.\n",
      "\n",
      "\t\t4. a woman is feeding something to a man\n",
      "\n",
      "\t\t5. A woman spoon feeding an old man\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/279108\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_no_rel_texts_blackout/0000000000000004_279108_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IN_FILE_NAME  = 'no_rel_texts_img_ids.pkl'\n",
    "OUT_FILE_NAME = 'no_rel_texts_blackout'\n",
    "get_expr_summary(in_file = IN_FILE_NAME, out_file = OUT_FILE_NAME, num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total:\t5600;\t\tMean:\t\t0.074113;\tNonezero:\t2767\n",
      "Median:\t0.000000;\tMedian(H):\t0.000000;\tMedian(L):\t0.000000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.113087\n",
      "\n",
      "\n",
      "[2]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:257350\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta close up of an orange and a apple;\n",
      "\tAblation Caption:\n",
      "\t\ta bus is parked in a parking lot;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. a group of people riding bikes stopped in front of a building\n",
      "\n",
      "\t\t2. A group of people on bicy les in front of a church.\n",
      "\n",
      "\t\t3. Bike riders on the corner outside of a church.\n",
      "\n",
      "\t\t4. Several children on bicycles outside a white church.\n",
      "\n",
      "\t\t5. Several people on bikes in front of a building.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/257350\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_rel_texts_blackout/0000000000000002_257350_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:311914\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta lunch box with a variety of food;\n",
      "\tAblation Caption:\n",
      "\t\ta man standing in front of a truck;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A school bus parked with it's stop sign closed.\n",
      "\n",
      "\t\t2. A stop sign is on the side of a school bus.\n",
      "\n",
      "\t\t3. a bus sits stopped with a sign on the side of it\n",
      "\n",
      "\t\t4. Side of a school bus showing a stop sign.\n",
      "\n",
      "\t\t5. A view of a stop sign, on the side of a bus.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/311914\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_rel_texts_blackout/0000000000000003_311914_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]Iamges with lowest scores:\n",
      "\n",
      "\tScore:0.0;\tImageId:462559\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta white van parked in front of a building;\n",
      "\tAblation Caption:\n",
      "\t\ta street sign on the side of the road;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. The sign tells motorists how to proceed on the street.\n",
      "\n",
      "\t\t2. A stop light is topped with a do not enter warning.\n",
      "\n",
      "\t\t3. A traffic light sitting below a do not enter sign.\n",
      "\n",
      "\t\t4. A stop light with a one way, do not enter sign above it.\n",
      "\n",
      "\t\t5. A large sign over a black stop light.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/462559\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_rel_texts_blackout/0000000000000012_462559_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IN_FILE_NAME  = 'rel_texts_img_ids.pkl'\n",
    "OUT_FILE_NAME = 'rel_texts_blackout'\n",
    "get_expr_summary(in_file = IN_FILE_NAME, out_file = OUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for scores of gaussian filtered ablations:\n",
      "\n",
      "Total:\t683;\t\tMean:\t\t0.818877;\tNonezero:\t681\n",
      "Median:\t1.000000;\tMedian(H):\t1.000000;\tMedian(L):\t1.000000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.279659\n",
      "\n",
      "\n",
      "[378]Zero Image\n",
      "\n",
      "\tScore:0.0;\tImageId:247708\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta person holding a cell phone in their hand;\n",
      "\tAblation Caption:\n",
      "\t\ta laptop computer sitting on top of a table;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. a person operating a cell phone near a laptop\n",
      "\n",
      "\t\t2. A laptop, smartphone, and iPad all on a table\n",
      "\n",
      "\t\t3. A person is calling someone on his phone regarding information on his laptop.\n",
      "\n",
      "\t\t4. A person working on a computer who is holding an iPhone.\n",
      "\n",
      "\t\t5. A person multitasking by using a laptop, phone, and tablet.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/247708\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_large_text_gaussian/0000000000000378_247708_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480]Zero Image\n",
      "\n",
      "\tScore:0.0;\tImageId:546211\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man is skiing down a snowy hill;\n",
      "\tAblation Caption:\n",
      "\t\ta group of people standing on top of a snow covered slope;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A skier is standing beside a rack of skis and snowboards.\n",
      "\n",
      "\t\t2. A skier looks at a wooden rack of skis at the bottom of a slope.\n",
      "\n",
      "\t\t3. A person on some skis in the snow.\n",
      "\n",
      "\t\t4. Skiers coming down a slope on a sunny day.\n",
      "\n",
      "\t\t5. A man skiing next to a ski rack.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/546211\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_large_text_gaussian/0000000000000480_546211_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]Zero Image\n",
      "\n",
      "\tScore:0.0833333333333;\tImageId:132883\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta street sign on a pole on a city street;\n",
      "\tAblation Caption:\n",
      "\t\ta red and white building with a clock on the side of it;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A red and white street sign sitting in front of a church.\n",
      "\n",
      "\t\t2. A sign with spray paint all over it .\n",
      "\n",
      "\t\t3. The sign describes the hours of the attraction.\n",
      "\n",
      "\t\t4. A red and white sign is all scribbled on.\n",
      "\n",
      "\t\t5. Vandalism on a sign with words that are not in English.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/132883\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_large_text_gaussian/0000000000000150_132883_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IN_FILE_NAME  = 'large_text_img_ids.pkl'\n",
    "OUT_FILE_NAME = 'large_text_gaussian'\n",
    "get_expr_summary(in_file = IN_FILE_NAME, out_file = OUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for scores of gaussian filtered ablations:\n",
      "\n",
      "Total:\t683;\t\tMean:\t\t0.521510;\tNonezero:\t630\n",
      "Median:\t0.500000;\tMedian(H):\t0.500000;\tMedian(L):\t0.500000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.352480\n",
      "\n",
      "\n",
      "[23]Zero Image\n",
      "\n",
      "\tScore:0.0;\tImageId:330436\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta man is doing a trick on a skateboard;\n",
      "\tAblation Caption:\n",
      "\t\ta person jumping a skate board in the air;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. a person jumping a skate board in the air\n",
      "\n",
      "\t\t2. This skateboarder is riding the side of his skateboard in the air.\n",
      "\n",
      "\t\t3. The young man is riding his skateboard practicing his moves.\n",
      "\n",
      "\t\t4. A skateboarder is airborne in front of a wall covered in graffiti.\n",
      "\n",
      "\t\t5. A person jumping in the air on a skateboard.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/330436\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_large_text_blackout/0000000000000023_330436_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]Zero Image\n",
      "\n",
      "\tScore:0.0;\tImageId:375294\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta couple of cell phones sitting on top of a table;\n",
      "\tAblation Caption:\n",
      "\t\ta person is holding a small piece of paper;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. there are 2 tablets, 1 e-reader, and an iphone sitting on the table.\n",
      "\n",
      "\t\t2. a table that has a bunch of ipads on it\n",
      "\n",
      "\t\t3. some different tablets cellphone and a piece of pizza\n",
      "\n",
      "\t\t4. Tablets and a cell phone on a table beside a plate of pizza.\n",
      "\n",
      "\t\t5. Some iPads and phone are on a table with pizza.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/375294\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_large_text_blackout/0000000000000027_375294_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]Zero Image\n",
      "\n",
      "\tScore:0.0;\tImageId:172316\n",
      "\n",
      "\tOriginal Caption:\n",
      "\t\ta young boy swinging a baseball bat at a ball;\n",
      "\tAblation Caption:\n",
      "\t\ta man standing in front of a wall with a cell phone;\n",
      "\tAnnotated Captions:\n",
      "\n",
      "\t\t1. A boy is swinging at a ball during a baseball game.\n",
      "\n",
      "\t\t2. A boy that is hitting a ball with a baseball bat.\n",
      "\n",
      "\t\t3. A person with a bat and helmet hits a ball.\n",
      "\n",
      "\t\t4. a boy in a yellow and white uniform hitting a baseball\n",
      "\n",
      "\t\t5. A young baseball player is hitting the ball.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "        <th><img src=\"http://mscoco.org/images/172316\" style=\"max-width:400px\" /></th>\n",
       "        <th><img src=\"tmp_large_text_blackout/0000000000000033_172316_ablt.jpg\" style=\"max-width:400px\" /></th>\n",
       "        </tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IN_FILE_NAME  = 'large_text_img_ids.pkl'\n",
    "OUT_FILE_NAME = 'large_text_blackout'\n",
    "get_expr_summary(in_file = IN_FILE_NAME, out_file = OUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis = json.load(open(os.path.join(OUT_DIR, 'vis_%s.json'%OUT_FILE_NAME)))\n",
    "scores  = cPickle.load(open(os.path.join(OUT_DIR, \"scores_%s.pkl\"%OUT_FILE_NAME)))\n",
    "in_ids  = cPickle.load(open(os.path.join(IN_DIR, IN_FILE_NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15980 32000 392136 16000\n",
      "no_rel_texts_blackout no_rel_texts_img_ids.pkl\n",
      "31960 15980\n"
     ]
    }
   ],
   "source": [
    "print len(in_ids), len(vis), in_ids[0], len(scores)\n",
    "print OUT_FILE_NAME, IN_FILE_NAME \n",
    "\n",
    "vp, sp = pre_process_vis(vis, scores, len(in_ids))\n",
    "print len(vp), len(sp)\n",
    "\n",
    "from semantic_dist import *\n",
    "ablated = [d['caption'] for d in vp[::2]]\n",
    "original = [d['caption'] for d in vp[1::2]]\n",
    "stoplist = set('for a of the and to in its his her'.split())\n",
    "ablated, original = pre_process(ablated, ignore=stoplist),pre_process(original, ignore=stoplist)\n",
    "new_sp = map(lambda x: calc_inter_union(*x), zip(ablated, original))\n",
    "\n",
    "assert len(sp) == len(new_sp)\n",
    "for i in range(len(sp)):\n",
    "    assert sp[i]==new_sp[i]\n",
    "#figuring out what is duplicated\n",
    "# from collections import defaultdict\n",
    "# s = defaultdict(int)\n",
    "# for d in vp:\n",
    "#     s[int(d['image_id'])] += 1\n",
    "# print len(s), len(l)\n",
    "# print l\n",
    "# print vis[0] == vis[-40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'246'}\n",
      "899 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'900'}\n",
      "913 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'914'}\n",
      "1565 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'1566'}\n",
      "2314 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'2315'}\n",
      "3230 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'3231'}\n",
      "3790 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'3791'}\n",
      "4213 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'4214'}\n",
      "4318 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'4319'}\n",
      "4583 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'4584'}\n",
      "4647 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'4648'}\n",
      "4666 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'4667'}\n",
      "4869 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'4870'}\n",
      "5334 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'5335'}\n",
      "5484 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'5485'}\n",
      "5653 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'5654'}\n",
      "6409 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'6410'}\n",
      "6886 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'6887'}\n",
      "7081 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'7082'}\n",
      "7190 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'7191'}\n",
      "7260 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'7261'}\n",
      "7275 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'7276'}\n",
      "7593 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'7594'}\n",
      "7769 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'7770'}\n",
      "8173 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'8174'}\n",
      "9682 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'9683'}\n",
      "10854 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'10855'}\n",
      "10882 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'10883'}\n",
      "11063 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'11064'}\n",
      "11479 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'11480'}\n",
      "11777 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'11778'}\n",
      "11851 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'11852'}\n",
      "12565 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'12566'}\n",
      "12786 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'12787'}\n",
      "12951 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'12952'}\n",
      "13346 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'13347'}\n",
      "13732 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'13733'}\n",
      "14433 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'14434'}\n",
      "14659 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'14660'}\n",
      "14699 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'14700'}\n",
      "17075 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'17076'}\n",
      "17423 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'17424'}\n",
      "17582 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'17583'}\n",
      "18298 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'18299'}\n",
      "19957 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'19958'}\n",
      "20303 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'20304'}\n",
      "20956 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'20957'}\n",
      "22229 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'22230'}\n",
      "23816 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'23817'}\n",
      "25151 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'25152'}\n",
      "26206 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'26207'}\n",
      "26374 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'26375'}\n",
      "26460 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'26461'}\n",
      "27539 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'27540'}\n",
      "28566 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'28567'}\n",
      "29675 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'29676'}\n",
      "30041 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'30042'}\n",
      "30065 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'30066'}\n",
      "30680 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'30681'}\n",
      "30855 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'30856'}\n",
      "31614 {u'caption': u'a group of people standing in front of a bus', u'image_id': u'31615'}\n",
      "15980 15980 True\n"
     ]
    }
   ],
   "source": [
    "for idx, d in enumerate(vp):\n",
    "    if 'a group of people standing in front of a bus' in d['caption']:\n",
    "        print idx, d\n",
    "print len(in_ids), len(set(in_ids)), 392136 in in_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
